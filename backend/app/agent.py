import json
import logging
import time

from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage
from langchain.agents import create_agent
from backend.app.config import DEEPSEEK_API_KEY, DEEPSEEK_BASE_URL, DEEPSEEK_MODEL
from backend.app.prompts import get_system_prompt
from backend.app.tools_manager import tools_manager
import backend.app.tools  # noqa: F401 â€” triggers tool registration
from backend.app.compact import was_compact_requested
from backend.app.background import drain_notifications
from backend.app.team import get_bus
from backend.app.team import state as _team_state
from backend.app.compaction import estimate_tokens, micro_compact, auto_compact
from backend.app.session import new_session_key, set_session_key, save_session
from backend.app import tracer

logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(name)s: %(message)s")

G = "\033[90m"
R = "\033[0m"

THRESHOLD = 50000

TOOL_ICONS = {
    "bash": "ğŸ’»", "read_file": "ğŸ“–", "write_file": "âœï¸", "edit_file": "âœï¸",
    "glob": "ğŸ”", "grep": "ğŸ”", "list_dir": "ğŸ“‚",
    "Task": "ğŸ¤–", "load_skill": "ğŸ“š", "compact": "ğŸ—œï¸",
    "task_create": "ğŸ“Œ", "task_get": "ğŸ”–", "task_update": "ğŸ”„", "task_list": "ğŸ“",
    "task_bind_worktree": "ğŸ”—",
    "background_run": "âš¡", "background_agent": "ğŸ¤–âš¡", "check_background": "ğŸ“¡",
    "worktree_create": "ğŸŒ¿", "worktree_list": "ğŸŒ³", "worktree_status": "ğŸ“Š",
    "worktree_run": "â–¶ï¸", "worktree_remove": "ğŸ—‘ï¸", "worktree_keep": "ğŸ“",
    "worktree_events": "ğŸ“œ",
}


def _log(icon: str, msg: str):
    print(f"{G}{icon} {msg}{R}")


def _fmt_args(name: str, args: dict) -> str:
    if name == "Task":
        return f"subagent={args.get('subagent_type')} | {args.get('description', '')[:60]}"
    if name == "TodoWrite":
        todos = args.get("todos", [])
        summary = ", ".join(f"{t.get('status','?')}:{t.get('content','')[:20]}" for t in todos[:4])
        return f"{len(todos)} todos [{summary}{'...' if len(todos)>4 else ''}]"
    if name == "spawn_teammate":
        return f"name={args.get('name')} role={args.get('role')}"
    if name in ("worktree_create", "worktree_run", "worktree_remove", "worktree_keep", "worktree_status"):
        return f"name={args.get('name')} task_id={args.get('task_id','-')}"
    if name == "background_run":
        return str(args.get("command", ""))[:80]
    if name == "background_agent":
        return f"subagent={args.get('subagent_type')} | {args.get('description', '')[:60]}"
    if name in ("task_create", "task_update"):
        return f"subject={args.get('subject','')} status={args.get('status','')}"
    return str(args)[:80]


def _build_agent(session_key: str = ""):
    llm = ChatOpenAI(
        model=DEEPSEEK_MODEL,
        api_key=DEEPSEEK_API_KEY,
        base_url=DEEPSEEK_BASE_URL,
    )
    return create_agent(llm, tools_manager.get_tools(), system_prompt=get_system_prompt(session_key)), llm


class AgentService:
    def __init__(self):
        self.session_key = new_session_key()
        set_session_key(self.session_key)
        self.agent, self.llm = _build_agent(self.session_key)
        self.rounds_without_todo = 0
        self.file_writes_since_reflect = 0  # æ–‡ä»¶å†™å…¥åæœªåæ€çš„æ¬¡æ•°
        self.reflect_retry_count = 0        # å½“å‰åæ€é‡è¯•æ¬¡æ•°
        _log("ğŸ¤–", f"Agent å°±ç»ª | æ¨¡å‹={DEEPSEEK_MODEL} | session={self.session_key}")

    def run(self, prompt: str, history: list = None) -> str:
        if history is None:
            history = []

        # Layer 1: micro_compact
        micro_compact(history)
        # Layer 2: auto_compact
        if estimate_tokens(history, self.llm) > THRESHOLD:
            _log("ğŸ—œï¸", "[auto_compact triggered]")
            tracer.emit("compaction", kind="auto", note=f"tokens>{THRESHOLD}")
            new_history = auto_compact(history, self.llm)
            history.clear()
            history.extend(new_history)

        # æ³¨å…¥ lead inbox æ¶ˆæ¯ï¼ˆä»…å½“ team å·²åˆå§‹åŒ–æ—¶ï¼Œé¿å…æå‰åˆ›å»º team ç›®å½•ï¼‰
        inbox = get_bus().read_inbox("lead") if _team_state._bus is not None else []
        if inbox and history:
            history.append(HumanMessage(content=f"<inbox>{json.dumps(inbox, indent=2)}</inbox>"))
            history.append(AIMessage(content="Noted inbox messages."))
            _log("ğŸ“¬", f"æ³¨å…¥ {len(inbox)} æ¡ inbox æ¶ˆæ¯")

        # æ³¨å…¥åå°ä»»åŠ¡å®Œæˆé€šçŸ¥
        notifs = drain_notifications()
        if notifs and history:
            notif_text = "\n".join(
                f"[bg:{n['task_id']}] {n['status']}: {n['result']}" for n in notifs
            )
            history.append(HumanMessage(content=f"<background-results>\n{notif_text}\n</background-results>"))
            history.append(AIMessage(content="Noted background results."))
            _log("ğŸ“¡", f"æ³¨å…¥ {len(notifs)} æ¡åå°ä»»åŠ¡é€šçŸ¥")

        _log("ğŸ‘¤", f"ç”¨æˆ·è¾“å…¥: {prompt}")
        run_start = time.time()
        rid = tracer.new_run_id()
        tracer.set_run_id(rid)
        tracer.emit("run.start", prompt=prompt, session=self.session_key)

        messages = history + [HumanMessage(content=prompt)]
        if self.rounds_without_todo >= 3:
            messages.append(HumanMessage(content="<reminder>è¯·æ›´æ–°ä½ çš„ TodoWrite å¾…åŠäº‹é¡¹ã€‚</reminder>"))
        if self.file_writes_since_reflect >= 1:
            retry_hint = f"ï¼ˆå·²é‡è¯• {self.reflect_retry_count} æ¬¡ï¼Œè‹¥ä» NEEDS_REVISION è¯·å‡çº§ä¸º Reflexionï¼‰" if self.reflect_retry_count >= 1 else ""
            messages.append(HumanMessage(
                content=f"<reflection-gate>ä½ åˆšå†™å…¥äº†æ–‡ä»¶ï¼Œå¿…é¡»å…ˆè°ƒç”¨ Task(subagent_type='Reflect') æ ¡éªŒåæ‰èƒ½ç»§ç»­ã€‚{retry_hint}</reflection-gate>"
            ))
        output = ""
        turn = 0
        total_tools = 0
        last_state_messages = messages
        tool_results_summary = []
        # track pending tool calls so we can match results with call_ids
        _pending_calls: dict[str, dict] = {}  # call_id -> {tool, t_start}

        for step in self.agent.stream({"messages": messages}, stream_mode="updates"):
            for node, state in step.items():
                last = state["messages"][-1]
                if node == "agent":
                    turn += 1
                    last_state_messages = state["messages"]
                    _log("ğŸ§ ", f"[ç¬¬ {turn} æ¬¡è°ƒç”¨ LLM] ä¸Šä¸‹æ–‡æ¶ˆæ¯æ•°={len(state['messages'])}")
                    if getattr(last, "tool_calls", None):
                        tcs = last.tool_calls
                        mode = "å¹¶è¡Œ" if len(tcs) > 1 else "ä¸²è¡Œ"
                        _log("ğŸ”€", f"  AI å†³ç­–: {mode}è°ƒç”¨ {len(tcs)} ä¸ªå·¥å…·")
                        decisions = []
                        for tc in tcs:
                            icon = TOOL_ICONS.get(tc["name"], "ğŸ”§")
                            _log("ğŸ”€", f"    {icon}[{tc['name']}] {_fmt_args(tc['name'], tc['args'])}")
                            decisions.append({"tool": tc["name"], "args": _fmt_args(tc["name"], tc["args"])})
                            call_id = tc.get("id") or tc["name"]
                            _pending_calls[call_id] = {"tool": tc["name"], "t_start": time.time()}
                            tracer.emit("tool.call", turn=turn, tool=tc["name"],
                                        args=tc["args"], call_id=call_id)
                        tracer.emit("llm.turn", turn=turn, msg_count=len(state["messages"]),
                                    decisions=decisions)
                    else:
                        output = last.content or output
                        _log("ğŸ§ ", f"  AI å†³ç­–: ç›´æ¥å›ç­”ï¼Œæ— éœ€å·¥å…·")
                        tracer.emit("llm.turn", turn=turn, msg_count=len(state["messages"]),
                                    direct_answer=True, output_preview=output[:200])
                elif node == "tools":
                    icon = TOOL_ICONS.get(last.name, "ğŸ”§")
                    _log("ğŸ“¥", f"  {icon}[{last.name}] è¿”å›: {last.content[:80]}")
                    tool_results_summary.append(last.content[:500])
                    total_tools += 1
                    # match call_id
                    call_id = getattr(last, "tool_call_id", last.name)
                    pending = _pending_calls.pop(call_id, _pending_calls.pop(last.name, None))
                    duration_ms = round((time.time() - pending["t_start"]) * 1000) if pending else None
                    tracer.emit("tool.result", turn=turn, tool=last.name, call_id=call_id,
                                duration_ms=duration_ms,
                                ok=not last.content.startswith("Error:"),
                                output=last.content[:500])
                    if last.name == "TodoWrite":
                        self.rounds_without_todo = 0
                    else:
                        self.rounds_without_todo += 1
                    # æ–‡ä»¶å†™å…¥è®¡æ•°å™¨
                    if last.name in ("write_file", "edit_file"):
                        self.file_writes_since_reflect += 1
                    # Reflect/Reflexion è°ƒç”¨åé‡ç½®è®¡æ•°å™¨
                    if last.name == "Task":
                        task_args = _pending_calls.get(call_id, {})
                        subagent = ""
                        # ä» tool call args é‡Œå– subagent_type
                        for tc in (last_state_messages[-1].tool_calls if getattr(last_state_messages[-1], "tool_calls", None) else []):
                            if tc.get("id") == call_id or tc.get("name") == "Task":
                                subagent = tc.get("args", {}).get("subagent_type", "")
                                break
                        if subagent in ("Reflect", "Reflexion"):
                            if "NEEDS_REVISION" in last.content:
                                self.reflect_retry_count += 1
                            else:
                                self.file_writes_since_reflect = 0
                                self.reflect_retry_count = 0
                        # è¶…è¿‡ 2 æ¬¡é‡è¯•å¼ºåˆ¶å‡çº§æç¤ºï¼ˆé‡ç½®è®¡æ•°é¿å…æ­»å¾ªç¯ï¼‰
                        if self.reflect_retry_count >= 2:
                            self.reflect_retry_count = 0
                            self.file_writes_since_reflect = 0
                    # drain after each tool batch (mirrors v7: drain before each LLM call)
                    notifs = drain_notifications()
                    if notifs:
                        notif_text = "\n".join(
                            f"[bg:{n['task_id']}] {n['status']}: {n['result']}" for n in notifs
                        )
                        messages = last_state_messages + [
                            HumanMessage(content=f"<background-results>\n{notif_text}\n</background-results>"),
                            AIMessage(content="Noted background results."),
                        ]
                        _log("ğŸ“¡", f"  åŒè½®æ³¨å…¥ {len(notifs)} æ¡åå°ä»»åŠ¡é€šçŸ¥")

        # DeepSeek sometimes returns empty content after tool use â€” call LLM once more
        if not output:
            _log("ğŸ§ ", "  [è¡¥å……è°ƒç”¨] è·å–æœ€ç»ˆå›ç­”")
            tool_context = "\n".join(f"- {r}" for r in tool_results_summary)
            fallback_messages = last_state_messages + [
                HumanMessage(content=f"å·¥å…·è°ƒç”¨ç»“æœå¦‚ä¸‹ï¼š\n{tool_context}\n\nè¯·æ ¹æ®ä»¥ä¸Šç»“æœï¼Œç”¨ä¸­æ–‡ç®€æ´åœ°å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼Œç›´æ¥å¼•ç”¨å·¥å…·è¿”å›çš„åŸå§‹æ•°æ®ï¼Œä¸è¦ç¼–é€ ä»»ä½•IDæˆ–æ•°å€¼ã€‚")
            ]
            t_fallback = time.time()
            resp = self.llm.invoke(fallback_messages)
            output = resp.content
            tracer.emit("llm.fallback", duration_ms=round((time.time() - t_fallback) * 1000),
                        output_preview=output[:200])

        history.append(HumanMessage(content=prompt))
        history.append(AIMessage(content=output))

        # Layer 3: manual compact triggered by compact tool
        if was_compact_requested():
            _log("ğŸ—œï¸", "[manual compact]")
            tracer.emit("compaction", kind="manual")
            new_history = auto_compact(history, self.llm)
            history.clear()
            history.extend(new_history)

        duration_ms = round((time.time() - run_start) * 1000)
        tracer.emit("run.end", output=output[:300], turns=turn,
                    total_tools=total_tools, duration_ms=duration_ms)
        _log("âœ…", f"AI æœ€ç»ˆå›ç­” â†’ {output[:120]}")
        save_session("main", history)
        return output
